{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.71285045 [[0.5889225]\n",
      " [0.3225816]]\n",
      "100 0.7011957 [[0.4113591 ]\n",
      " [0.26869902]]\n",
      "200 0.6967913 [[0.26893994]\n",
      " [0.19268267]]\n",
      "300 0.6947986 [[0.17640427]\n",
      " [0.13565664]]\n",
      "400 0.6938964 [[0.11627143]\n",
      " [0.09450126]]\n",
      "500 0.69348764 [[0.07696913]\n",
      " [0.06533869]]\n",
      "600 0.693302 [[0.05113969]\n",
      " [0.04492645]]\n",
      "700 0.6932176 [[0.03408226]\n",
      " [0.03076307]]\n",
      "800 0.69317925 [[0.02277135]\n",
      " [0.02099818]]\n",
      "900 0.6931618 [[0.01524525]\n",
      " [0.01429802]]\n",
      "1000 0.69315386 [[0.01022339]\n",
      " [0.00971737]]\n",
      "1100 0.6931502 [[0.00686482]\n",
      " [0.00659451]]\n",
      "1200 0.69314855 [[0.00461449]\n",
      " [0.0044701 ]]\n",
      "1300 0.69314784 [[0.00310447]\n",
      " [0.00302733]]\n",
      "1400 0.6931474 [[0.00208997]\n",
      " [0.00204877]]\n",
      "1500 0.6931473 [[0.00140777]\n",
      " [0.00138576]]\n",
      "1600 0.69314724 [[0.00094867]\n",
      " [0.00093692]]\n",
      "1700 0.6931472 [[0.00063948]\n",
      " [0.0006332 ]]\n",
      "1800 0.6931472 [[0.00043124]\n",
      " [0.00042789]]\n",
      "1900 0.6931472 [[0.00029082]\n",
      " [0.00028903]]\n",
      "2000 0.6931472 [[0.00019616]\n",
      " [0.0001952 ]]\n",
      "2100 0.6931472 [[0.00013233]\n",
      " [0.00013182]]\n",
      "2200 0.6931472 [[8.927810e-05]\n",
      " [8.900487e-05]]\n",
      "2300 0.6931471 [[6.0235732e-05]\n",
      " [6.0093644e-05]]\n",
      "2400 0.6931472 [[4.0642208e-05]\n",
      " [4.0564184e-05]]\n",
      "2500 0.69314724 [[2.7424870e-05]\n",
      " [2.7381122e-05]]\n",
      "2600 0.6931472 [[1.8499080e-05]\n",
      " [1.8479172e-05]]\n",
      "2700 0.6931472 [[1.2479008e-05]\n",
      " [1.2466549e-05]]\n",
      "2800 0.6931472 [[8.413971e-06]\n",
      " [8.408963e-06]]\n",
      "2900 0.6931472 [[5.6661993e-06]\n",
      " [5.6641716e-06]]\n",
      "3000 0.6931472 [[3.8318635e-06]\n",
      " [3.8313260e-06]]\n",
      "3100 0.6931472 [[2.5712275e-06]\n",
      " [2.5706900e-06]]\n",
      "3200 0.6931472 [[1.7486798e-06]\n",
      " [1.7481423e-06]]\n",
      "3300 0.6931472 [[1.1809428e-06]\n",
      " [1.1804053e-06]]\n",
      "3400 0.6931472 [[7.771196e-07]\n",
      " [7.765821e-07]]\n",
      "3500 0.6931472 [[5.1336878e-07]\n",
      " [5.1283126e-07]]\n",
      "3600 0.6931472 [[3.6435728e-07]\n",
      " [3.6381977e-07]]\n",
      "3700 0.6931472 [[2.1981546e-07]\n",
      " [2.1927795e-07]]\n",
      "3800 0.6931472 [[1.6468096e-07]\n",
      " [1.6414344e-07]]\n",
      "3900 0.6931472 [[1.3189828e-07]\n",
      " [1.3136076e-07]]\n",
      "4000 0.6931472 [[1.0656627e-07]\n",
      " [1.0602876e-07]]\n",
      "4100 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4200 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4300 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4400 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4500 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4600 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4700 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4800 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "4900 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5000 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5100 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5200 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5300 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5400 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5500 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5600 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5700 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5800 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "5900 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6000 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6100 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6200 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6300 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6400 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6500 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6600 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6700 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6800 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "6900 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7000 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7100 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7200 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7300 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7400 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7500 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7600 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7700 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7800 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "7900 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8000 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8100 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8200 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8300 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8400 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8500 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8600 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8700 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8800 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "8900 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9000 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9100 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9200 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9300 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9400 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9500 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9600 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9700 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9800 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "9900 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "10000 0.6931472 [[8.868489e-08]\n",
      " [8.814738e-08]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0],    [1],    [1],    [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(X,W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "#  Accuracy\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data,Y:y_data}), sess.run(W))\n",
    "            \n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data,Y:y_data})\n",
    "    print(\"\\nHypothesis: \",h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.813231\n",
      "100 0.70261335\n",
      "200 0.6960683\n",
      "300 0.6880392\n",
      "400 0.6776238\n",
      "500 0.6660466\n",
      "600 0.6545329\n",
      "700 0.64297915\n",
      "800 0.6308124\n",
      "900 0.6176512\n",
      "1000 0.60342664\n",
      "1100 0.58829623\n",
      "1200 0.5724945\n",
      "1300 0.55618787\n",
      "1400 0.53937423\n",
      "1500 0.52184\n",
      "1600 0.5031615\n",
      "1700 0.4827541\n",
      "1800 0.45997807\n",
      "1900 0.4343121\n",
      "2000 0.40557218\n",
      "2100 0.37411475\n",
      "2200 0.3409091\n",
      "2300 0.3073729\n",
      "2400 0.2750004\n",
      "2500 0.24498439\n",
      "2600 0.21802571\n",
      "2700 0.19435191\n",
      "2800 0.17385404\n",
      "2900 0.15623696\n",
      "3000 0.14113382\n",
      "3100 0.12817489\n",
      "3200 0.117022395\n",
      "3300 0.107382625\n",
      "3400 0.09900829\n",
      "3500 0.09169398\n",
      "3600 0.08527058\n",
      "3700 0.079598956\n",
      "3800 0.074564904\n",
      "3900 0.0700745\n",
      "4000 0.06604998\n",
      "4100 0.062426794\n",
      "4200 0.05915124\n",
      "4300 0.056178212\n",
      "4400 0.05346972\n",
      "4500 0.05099362\n",
      "4600 0.048722554\n",
      "4700 0.04663313\n",
      "4800 0.0447053\n",
      "4900 0.042921737\n",
      "5000 0.041267335\n",
      "5100 0.03972917\n",
      "5200 0.03829576\n",
      "5300 0.036957096\n",
      "5400 0.035704404\n",
      "5500 0.034529913\n",
      "5600 0.033426747\n",
      "5700 0.03238876\n",
      "5800 0.031410467\n",
      "5900 0.030487131\n",
      "6000 0.029614262\n",
      "6100 0.02878794\n",
      "6200 0.028004678\n",
      "6300 0.02726125\n",
      "6400 0.026554748\n",
      "6500 0.025882624\n",
      "6600 0.025242375\n",
      "6700 0.024631953\n",
      "6800 0.024049275\n",
      "6900 0.023492597\n",
      "7000 0.02296023\n",
      "7100 0.022450615\n",
      "7200 0.021962356\n",
      "7300 0.021494234\n",
      "7400 0.021045007\n",
      "7500 0.020613555\n",
      "7600 0.020198846\n",
      "7700 0.019800104\n",
      "7800 0.01941623\n",
      "7900 0.019046554\n",
      "8000 0.01869027\n",
      "8100 0.018346602\n",
      "8200 0.018015089\n",
      "8300 0.017694939\n",
      "8400 0.017385643\n",
      "8500 0.01708672\n",
      "8600 0.016797587\n",
      "8700 0.01651781\n",
      "8800 0.016246956\n",
      "8900 0.01598461\n",
      "9000 0.015730403\n",
      "9100 0.015483905\n",
      "9200 0.015244836\n",
      "9300 0.0150128445\n",
      "9400 0.014787621\n",
      "9500 0.01456889\n",
      "9600 0.014356346\n",
      "9700 0.014149818\n",
      "9800 0.013948969\n",
      "9900 0.013753644\n",
      "10000 0.013563509\n",
      "\n",
      "Hypothesis: [[0.01607904]\n",
      " [0.98775524]\n",
      " [0.9877467 ]\n",
      " [0.01329836]] \n",
      "Predicted: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    print(\"\\nHypothesis:\",h,\"\\nPredicted:\",p,\"\\nAccuracy:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.83253956\n",
      "100 0.70758045\n",
      "200 0.6810137\n",
      "300 0.658406\n",
      "400 0.63316154\n",
      "500 0.6001287\n",
      "600 0.5590154\n",
      "700 0.5144127\n",
      "800 0.4686594\n",
      "900 0.42259282\n",
      "1000 0.37744653\n",
      "1100 0.33466113\n",
      "1200 0.29539514\n",
      "1300 0.26030904\n",
      "1400 0.22958323\n",
      "1500 0.20304453\n",
      "1600 0.18031108\n",
      "1700 0.16091226\n",
      "1800 0.14436702\n",
      "1900 0.1302291\n",
      "2000 0.11810629\n",
      "2100 0.107664645\n",
      "2200 0.09862575\n",
      "2300 0.09075938\n",
      "2400 0.08387653\n",
      "2500 0.07782224\n",
      "2600 0.07246915\n",
      "2700 0.067712605\n",
      "2800 0.06346607\n",
      "2900 0.059657887\n",
      "3000 0.056228265\n",
      "3100 0.05312734\n",
      "3200 0.0503129\n",
      "3300 0.047749415\n",
      "3400 0.045406856\n",
      "3500 0.043259274\n",
      "3600 0.04128468\n",
      "3700 0.03946412\n",
      "3800 0.03778106\n",
      "3900 0.03622135\n",
      "4000 0.034772493\n",
      "4100 0.033423617\n",
      "4200 0.032165233\n",
      "4300 0.030988913\n",
      "4400 0.02988718\n",
      "4500 0.028853547\n",
      "4600 0.027882094\n",
      "4700 0.026967533\n",
      "4800 0.026105408\n",
      "4900 0.025291273\n",
      "5000 0.024521595\n",
      "5100 0.023792822\n",
      "5200 0.023101933\n",
      "5300 0.022446215\n",
      "5400 0.021823108\n",
      "5500 0.021230303\n",
      "5600 0.020665765\n",
      "5700 0.020127555\n",
      "5800 0.019613946\n",
      "5900 0.019123415\n",
      "6000 0.018654387\n",
      "6100 0.018205581\n",
      "6200 0.017775778\n",
      "6300 0.017363809\n",
      "6400 0.016968617\n",
      "6500 0.016589284\n",
      "6600 0.016224861\n",
      "6700 0.01587454\n",
      "6800 0.015537487\n",
      "6900 0.015213078\n",
      "7000 0.014900543\n",
      "7100 0.014599366\n",
      "7200 0.014308871\n",
      "7300 0.01402856\n",
      "7400 0.013757988\n",
      "7500 0.013496522\n",
      "7600 0.013243852\n",
      "7700 0.012999471\n",
      "7800 0.01276304\n",
      "7900 0.012534236\n",
      "8000 0.0123126265\n",
      "8100 0.01209789\n",
      "8200 0.011889812\n",
      "8300 0.011688007\n",
      "8400 0.011492214\n",
      "8500 0.011302235\n",
      "8600 0.011117748\n",
      "8700 0.010938613\n",
      "8800 0.010764555\n",
      "8900 0.010595377\n",
      "9000 0.010430833\n",
      "9100 0.010270873\n",
      "9200 0.010115137\n",
      "9300 0.009963635\n",
      "9400 0.009816093\n",
      "9500 0.009672452\n",
      "9600 0.00953251\n",
      "9700 0.009396087\n",
      "9800 0.00926318\n",
      "9900 0.009133488\n",
      "10000 0.009007082\n",
      "\n",
      "Hypothesis: [[0.00320813]\n",
      " [0.98941636]\n",
      " [0.9913757 ]\n",
      " [0.0134173 ]] \n",
      "Predicted: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    print(\"\\nHypothesis:\",h,\"\\nPredicted:\",p,\"\\nAccuracy:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.87040293\n",
      "100 0.68488836\n",
      "200 0.6808562\n",
      "300 0.67602724\n",
      "400 0.66988283\n",
      "500 0.6615466\n",
      "600 0.6495451\n",
      "700 0.6316304\n",
      "800 0.60487443\n",
      "900 0.56586385\n",
      "1000 0.5107396\n",
      "1100 0.43714365\n",
      "1200 0.35136312\n",
      "1300 0.27048492\n",
      "1400 0.20686808\n",
      "1500 0.16072914\n",
      "1600 0.12770359\n",
      "1700 0.10376547\n",
      "1800 0.086058915\n",
      "1900 0.07267173\n",
      "2000 0.06233315\n",
      "2100 0.054190475\n",
      "2200 0.047662344\n",
      "2300 0.042344853\n",
      "2400 0.037951693\n",
      "2500 0.034276266\n",
      "2600 0.031166608\n",
      "2700 0.028509032\n",
      "2800 0.026217297\n",
      "2900 0.024224918\n",
      "3000 0.022480188\n",
      "3100 0.02094196\n",
      "3200 0.019577678\n",
      "3300 0.018360928\n",
      "3400 0.017270243\n",
      "3500 0.016287997\n",
      "3600 0.015399572\n",
      "3700 0.014592841\n",
      "3800 0.013857588\n",
      "3900 0.013185136\n",
      "4000 0.012568207\n",
      "4100 0.012000588\n",
      "4200 0.011476721\n",
      "4300 0.010992079\n",
      "4400 0.010542628\n",
      "4500 0.010124766\n",
      "4600 0.009735523\n",
      "4700 0.009372123\n",
      "4800 0.009032253\n",
      "4900 0.008713741\n",
      "5000 0.008414762\n",
      "5100 0.008133616\n",
      "5200 0.007868905\n",
      "5300 0.0076192203\n",
      "5400 0.0073833503\n",
      "5500 0.0071603083\n",
      "5600 0.006949081\n",
      "5700 0.0067488058\n",
      "5800 0.00655868\n",
      "5900 0.0063779643\n",
      "6000 0.006206098\n",
      "6100 0.006042342\n",
      "6200 0.005886228\n",
      "6300 0.0057372423\n",
      "6400 0.005594933\n",
      "6500 0.0054589063\n",
      "6600 0.005328741\n",
      "6700 0.0052041197\n",
      "6800 0.005084592\n",
      "6900 0.004969976\n",
      "7000 0.0048600296\n",
      "7100 0.0047543626\n",
      "7200 0.0046528094\n",
      "7300 0.0045550684\n",
      "7400 0.004461154\n",
      "7500 0.004370571\n",
      "7600 0.0042832587\n",
      "7700 0.0041991565\n",
      "7800 0.004117964\n",
      "7900 0.004039621\n",
      "8000 0.0039639473\n",
      "8100 0.0038908222\n",
      "8200 0.003820081\n",
      "8300 0.0037516933\n",
      "8400 0.0036854339\n",
      "8500 0.0036213775\n",
      "8600 0.0035592993\n",
      "8700 0.0034990942\n",
      "8800 0.0034407617\n",
      "8900 0.003384212\n",
      "9000 0.00332931\n",
      "9100 0.0032760256\n",
      "9200 0.003224269\n",
      "9300 0.0031740102\n",
      "9400 0.003125114\n",
      "9500 0.003077655\n",
      "9600 0.0030314391\n",
      "9700 0.0029865555\n",
      "9800 0.0029427947\n",
      "9900 0.0029002316\n",
      "10000 0.0028588206\n",
      "\n",
      "Hypothesis:  [[0.0026072 ]\n",
      " [0.9972395 ]\n",
      " [0.99687904]\n",
      " [0.00292844]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
