{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수, 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X,W) +b))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost 값 최소로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "\n",
    "train =  tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측값은 Binary로 변경, 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) # cast함수는 True면 1  False면 0을 해줌\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.5741323\n",
      "200 0.69663006\n",
      "400 0.6613554\n",
      "600 0.63232535\n",
      "800 0.6067586\n",
      "1000 0.58335966\n",
      "1200 0.5614895\n",
      "1400 0.5408178\n",
      "1600 0.5211671\n",
      "1800 0.5024373\n",
      "2000 0.48456752\n",
      "2200 0.46751645\n",
      "2400 0.45125198\n",
      "2600 0.43574575\n",
      "2800 0.42097095\n",
      "3000 0.4069004\n",
      "3200 0.39350617\n",
      "3400 0.38076022\n",
      "3600 0.36863387\n",
      "3800 0.35709834\n",
      "4000 0.34612504\n",
      "4200 0.33568573\n",
      "4400 0.32575268\n",
      "4600 0.31629905\n",
      "4800 0.30729914\n",
      "5000 0.29872787\n",
      "5200 0.29056144\n",
      "5400 0.2827771\n",
      "5600 0.27535346\n",
      "5800 0.2682699\n",
      "6000 0.2615073\n",
      "6200 0.25504735\n",
      "6400 0.24887295\n",
      "6600 0.2429678\n",
      "6800 0.23731695\n",
      "7000 0.23190594\n",
      "7200 0.22672164\n",
      "7400 0.22175132\n",
      "7600 0.2169834\n",
      "7800 0.21240677\n",
      "8000 0.20801099\n",
      "8200 0.20378654\n",
      "8400 0.19972433\n",
      "8600 0.19581592\n",
      "8800 0.19205314\n",
      "9000 0.18842864\n",
      "9200 0.18493539\n",
      "9400 0.1815667\n",
      "9600 0.17831637\n",
      "9800 0.17517872\n",
      "10000 0.17214817\n",
      "\n",
      "Hypothesis:  [[0.04081017]\n",
      " [0.1705893 ]\n",
      " [0.34991977]\n",
      " [0.7614881 ]\n",
      " [0.92635566]\n",
      " [0.9758405 ]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initalize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.0907032\n",
      "200 0.68266153\n",
      "400 0.4781454\n",
      "600 0.39697003\n",
      "800 0.35876143\n",
      "1000 0.33662716\n",
      "1200 0.3213856\n",
      "1400 0.3094982\n",
      "1600 0.29944256\n",
      "1800 0.2905033\n",
      "2000 0.28231898\n",
      "2200 0.27469483\n",
      "2400 0.26751885\n",
      "2600 0.26072276\n",
      "2800 0.25426105\n",
      "3000 0.24810158\n",
      "3200 0.24221992\n",
      "3400 0.23659627\n",
      "3600 0.23121376\n",
      "3800 0.22605781\n",
      "4000 0.22111501\n",
      "4200 0.21637331\n",
      "4400 0.21182169\n",
      "4600 0.20744967\n",
      "4800 0.20324756\n",
      "5000 0.19920646\n",
      "5200 0.19531788\n",
      "5400 0.19157387\n",
      "5600 0.1879671\n",
      "5800 0.1844907\n",
      "6000 0.1811379\n",
      "6200 0.1779027\n",
      "6400 0.17477934\n",
      "6600 0.17176247\n",
      "6800 0.1688468\n",
      "7000 0.16602772\n",
      "7200 0.16330056\n",
      "7400 0.16066119\n",
      "7600 0.1581055\n",
      "7800 0.1556298\n",
      "8000 0.15323044\n",
      "8200 0.15090412\n",
      "8400 0.14864759\n",
      "8600 0.14645784\n",
      "8800 0.14433205\n",
      "9000 0.14226747\n",
      "9200 0.14026165\n",
      "9400 0.13831215\n",
      "9600 0.13641654\n",
      "9800 0.13457286\n",
      "10000 0.13277891\n",
      "\n",
      "Hypothesis:  [[0.02403596]\n",
      " [0.14862943]\n",
      " [0.2709632 ]\n",
      " [0.79732907]\n",
      " [0.94917583]\n",
      " [0.9834359 ]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1]) \n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X,W) +b))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "\n",
    "train =  tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) # cast함수는 True면 1  False면 0을 해줌\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initalize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying diabetes 실습연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 데이터 수 759\n",
    "# 학습 데이터 수 460\n",
    "# 테스트 데이터 수 299\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_train_data = xy[:460, 0:-1]\n",
    "y_train_data = xy[:460, [-1]]\n",
    "x_test_data = xy[460:, 0:-1]\n",
    "y_test_data = xy[460:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7156238\n",
      "200 0.6397457\n",
      "400 0.61806893\n",
      "600 0.6045003\n",
      "800 0.59334105\n",
      "1000 0.5836562\n",
      "1200 0.5751555\n",
      "1400 0.5676599\n",
      "1600 0.5610271\n",
      "1800 0.55513746\n",
      "2000 0.5498894\n",
      "2200 0.5451972\n",
      "2400 0.54098797\n",
      "2600 0.5372001\n",
      "2800 0.5337804\n",
      "3000 0.5306841\n",
      "3200 0.52787286\n",
      "3400 0.5253131\n",
      "3600 0.52297664\n",
      "3800 0.52083874\n",
      "4000 0.518878\n",
      "4200 0.51707584\n",
      "4400 0.5154161\n",
      "4600 0.51388437\n",
      "4800 0.51246816\n",
      "5000 0.5111567\n",
      "5200 0.50994\n",
      "5400 0.5088097\n",
      "5600 0.50775784\n",
      "5800 0.5067778\n",
      "6000 0.50586337\n",
      "6200 0.5050092\n",
      "6400 0.5042101\n",
      "6600 0.50346196\n",
      "6800 0.5027606\n",
      "7000 0.50210255\n",
      "7200 0.50148433\n",
      "7400 0.5009032\n",
      "7600 0.5003563\n",
      "7800 0.4998413\n",
      "8000 0.49935585\n",
      "8200 0.49889788\n",
      "8400 0.49846557\n",
      "8600 0.49805713\n",
      "8800 0.497671\n",
      "9000 0.49730575\n",
      "9200 0.4969601\n",
      "9400 0.4966326\n",
      "9600 0.4963222\n",
      "9800 0.49602783\n",
      "10000 0.4957487\n",
      "\n",
      "Hypothesis:  [[0.69351995]\n",
      " [0.62785417]\n",
      " [0.25844452]\n",
      " [0.42064947]\n",
      " [0.50580597]\n",
      " [0.5717782 ]\n",
      " [0.51809543]\n",
      " [0.7542087 ]\n",
      " [0.5963751 ]\n",
      " [0.73456866]\n",
      " [0.8234781 ]\n",
      " [0.7240422 ]\n",
      " [0.6627146 ]\n",
      " [0.4755884 ]\n",
      " [0.54775715]\n",
      " [0.9221703 ]\n",
      " [0.7877074 ]\n",
      " [0.2250829 ]\n",
      " [0.37971777]\n",
      " [0.47532618]\n",
      " [0.10389936]\n",
      " [0.8815668 ]\n",
      " [0.18456125]\n",
      " [0.86517894]\n",
      " [0.85064423]\n",
      " [0.8059291 ]\n",
      " [0.6834457 ]\n",
      " [0.85784113]\n",
      " [0.3936469 ]\n",
      " [0.7612631 ]\n",
      " [0.9232632 ]\n",
      " [0.34904104]\n",
      " [0.44566748]\n",
      " [0.865885  ]\n",
      " [0.8378346 ]\n",
      " [0.60974413]\n",
      " [0.78360933]\n",
      " [0.7721572 ]\n",
      " [0.76355195]\n",
      " [0.26334584]\n",
      " [0.76230145]\n",
      " [0.88685477]\n",
      " [0.63643646]\n",
      " [0.7766988 ]\n",
      " [0.73536104]\n",
      " [0.8082333 ]\n",
      " [0.84555197]\n",
      " [0.92172897]\n",
      " [0.5921128 ]\n",
      " [0.4177162 ]\n",
      " [0.74127394]\n",
      " [0.78997624]\n",
      " [0.9573574 ]\n",
      " [0.72615814]\n",
      " [0.6590301 ]\n",
      " [0.39863396]\n",
      " [0.68750453]\n",
      " [0.9257772 ]\n",
      " [0.9500646 ]\n",
      " [0.8804312 ]\n",
      " [0.67196244]\n",
      " [0.6592252 ]\n",
      " [0.79075885]\n",
      " [0.39517468]\n",
      " [0.74441665]\n",
      " [0.773588  ]\n",
      " [0.8666756 ]\n",
      " [0.5833114 ]\n",
      " [0.680252  ]\n",
      " [0.8945203 ]\n",
      " [0.44767278]\n",
      " [0.47844496]\n",
      " [0.6022409 ]\n",
      " [0.70156986]\n",
      " [0.6341187 ]\n",
      " [0.8603684 ]\n",
      " [0.8993472 ]\n",
      " [0.20940483]\n",
      " [0.13766518]\n",
      " [0.73343587]\n",
      " [0.5023879 ]\n",
      " [0.25740927]\n",
      " [0.8373449 ]\n",
      " [0.8776913 ]\n",
      " [0.6914935 ]\n",
      " [0.91875154]\n",
      " [0.88762015]\n",
      " [0.75385576]\n",
      " [0.7961585 ]\n",
      " [0.68801916]\n",
      " [0.4890405 ]\n",
      " [0.73349464]\n",
      " [0.5843417 ]\n",
      " [0.11978766]\n",
      " [0.8644277 ]\n",
      " [0.868624  ]\n",
      " [0.6739711 ]\n",
      " [0.90799   ]\n",
      " [0.8256999 ]\n",
      " [0.8604789 ]\n",
      " [0.5729114 ]\n",
      " [0.657059  ]\n",
      " [0.8575816 ]\n",
      " [0.7306095 ]\n",
      " [0.8315151 ]\n",
      " [0.88449025]\n",
      " [0.5783411 ]\n",
      " [0.75977963]\n",
      " [0.8311652 ]\n",
      " [0.49059474]\n",
      " [0.52800894]\n",
      " [0.09945554]\n",
      " [0.23748207]\n",
      " [0.8281958 ]\n",
      " [0.6640947 ]\n",
      " [0.6202213 ]\n",
      " [0.5815437 ]\n",
      " [0.9346174 ]\n",
      " [0.42270425]\n",
      " [0.7990521 ]\n",
      " [0.2880938 ]\n",
      " [0.8863615 ]\n",
      " [0.28969476]\n",
      " [0.7053056 ]\n",
      " [0.54694223]\n",
      " [0.845591  ]\n",
      " [0.5503929 ]\n",
      " [0.25105518]\n",
      " [0.7148602 ]\n",
      " [0.9333757 ]\n",
      " [0.36267564]\n",
      " [0.9169477 ]\n",
      " [0.8578286 ]\n",
      " [0.83910996]\n",
      " [0.79640186]\n",
      " [0.41144386]\n",
      " [0.34150627]\n",
      " [0.67764014]\n",
      " [0.17357498]\n",
      " [0.94461256]\n",
      " [0.30153129]\n",
      " [0.91883445]\n",
      " [0.86116564]\n",
      " [0.43062323]\n",
      " [0.1978373 ]\n",
      " [0.6698826 ]\n",
      " [0.42288876]\n",
      " [0.81642973]\n",
      " [0.67509496]\n",
      " [0.97527885]\n",
      " [0.5646627 ]\n",
      " [0.60102904]\n",
      " [0.72073156]\n",
      " [0.8029786 ]\n",
      " [0.0753704 ]\n",
      " [0.6871906 ]\n",
      " [0.7874078 ]\n",
      " [0.78246796]\n",
      " [0.6437552 ]\n",
      " [0.45645216]\n",
      " [0.56994575]\n",
      " [0.90264773]\n",
      " [0.6259817 ]\n",
      " [0.72319406]\n",
      " [0.7999434 ]\n",
      " [0.843377  ]\n",
      " [0.7845904 ]\n",
      " [0.5465433 ]\n",
      " [0.77256346]\n",
      " [0.8758341 ]\n",
      " [0.6343946 ]\n",
      " [0.95267916]\n",
      " [0.77219796]\n",
      " [0.58059925]\n",
      " [0.49098575]\n",
      " [0.810349  ]\n",
      " [0.8290361 ]\n",
      " [0.44647977]\n",
      " [0.676984  ]\n",
      " [0.23095587]\n",
      " [0.5533949 ]\n",
      " [0.80372167]\n",
      " [0.9378606 ]\n",
      " [0.80597794]\n",
      " [0.68077487]\n",
      " [0.74432296]\n",
      " [0.85525835]\n",
      " [0.48430705]\n",
      " [0.92118895]\n",
      " [0.51817554]\n",
      " [0.80466896]\n",
      " [0.33406746]\n",
      " [0.08582294]\n",
      " [0.25596422]\n",
      " [0.31697637]\n",
      " [0.676308  ]\n",
      " [0.77784383]\n",
      " [0.6057235 ]\n",
      " [0.7377309 ]\n",
      " [0.78202486]\n",
      " [0.49329096]\n",
      " [0.38584095]\n",
      " [0.9045326 ]\n",
      " [0.85324514]\n",
      " [0.2904059 ]\n",
      " [0.6402662 ]\n",
      " [0.20006278]\n",
      " [0.41772938]\n",
      " [0.69639933]\n",
      " [0.66582334]\n",
      " [0.89587975]\n",
      " [0.9703444 ]\n",
      " [0.16290441]\n",
      " [0.63599867]\n",
      " [0.5765575 ]\n",
      " [0.44334078]\n",
      " [0.6926896 ]\n",
      " [0.7291284 ]\n",
      " [0.88639414]\n",
      " [0.72550386]\n",
      " [0.41973624]\n",
      " [0.6478313 ]\n",
      " [0.14039043]\n",
      " [0.62099814]\n",
      " [0.48076686]\n",
      " [0.89756817]\n",
      " [0.57120657]\n",
      " [0.5665479 ]\n",
      " [0.77636373]\n",
      " [0.6920337 ]\n",
      " [0.40253422]\n",
      " [0.71060836]\n",
      " [0.65397525]\n",
      " [0.33926338]\n",
      " [0.56754947]\n",
      " [0.86528146]\n",
      " [0.7877345 ]\n",
      " [0.5574291 ]\n",
      " [0.76493776]\n",
      " [0.2932416 ]\n",
      " [0.80059826]\n",
      " [0.6005643 ]\n",
      " [0.7340083 ]\n",
      " [0.38286993]\n",
      " [0.6748016 ]\n",
      " [0.8086355 ]\n",
      " [0.19146895]\n",
      " [0.29280585]\n",
      " [0.81860375]\n",
      " [0.7704872 ]\n",
      " [0.7671956 ]\n",
      " [0.89174986]\n",
      " [0.7499121 ]\n",
      " [0.68949026]\n",
      " [0.673111  ]\n",
      " [0.7357332 ]\n",
      " [0.645639  ]\n",
      " [0.74944156]\n",
      " [0.47602963]\n",
      " [0.4613398 ]\n",
      " [0.86138844]\n",
      " [0.7785561 ]\n",
      " [0.61501557]\n",
      " [0.24221814]\n",
      " [0.8610888 ]\n",
      " [0.81343806]\n",
      " [0.80353   ]\n",
      " [0.66182387]\n",
      " [0.8656741 ]\n",
      " [0.84393615]\n",
      " [0.7204524 ]\n",
      " [0.3687426 ]\n",
      " [0.87583977]\n",
      " [0.8969668 ]\n",
      " [0.32445747]\n",
      " [0.14843085]\n",
      " [0.69718206]\n",
      " [0.32712543]\n",
      " [0.7176134 ]\n",
      " [0.3267433 ]\n",
      " [0.48429605]\n",
      " [0.42155007]\n",
      " [0.710595  ]\n",
      " [0.86202526]\n",
      " [0.13009629]\n",
      " [0.38581887]\n",
      " [0.55910325]\n",
      " [0.48422337]\n",
      " [0.48932675]\n",
      " [0.7352    ]\n",
      " [0.17095268]\n",
      " [0.89911425]\n",
      " [0.17757773]\n",
      " [0.84001565]\n",
      " [0.6893761 ]\n",
      " [0.6938568 ]\n",
      " [0.815636  ]\n",
      " [0.70346   ]\n",
      " [0.87567306]] \n",
      "Correct (Y):  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.78595316\n"
     ]
    }
   ],
   "source": [
    "#변수설정\n",
    "X = tf.placeholder(tf.float32, shape=[None,8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1]) \n",
    "W = tf.Variable(tf.random_normal([8,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "# 함수만들기\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "# 차이의 제곱평균구하기\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "# 차이의 제곱평균이 최소가 되도록 학습\n",
    "train =  tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "# 정확도계산\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_train_data, Y:y_train_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_test_data, Y:y_test_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
