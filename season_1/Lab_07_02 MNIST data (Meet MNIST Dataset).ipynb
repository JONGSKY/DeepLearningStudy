{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading data and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\envs\\inflearn\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) \n",
    "# one_hot을 true로 하면 y값을 별도로 one_hote을 해주지 않아도 만들어줌\n",
    "\n",
    "nb_classes = 10 # 0~9까지의 수이기 때문에 10임\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis (using softmax)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1)) # Y는 one_hot으로 설정되어 있음\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training epoch/batch\n",
    "In the neural network terminology:\n",
    "    - one epoch = one forward pass and one backward pass of all the training examples\n",
    "    (한번 trainset데이터를 학습시키는 것을 one epoch라함) \n",
    "    - batch size = the number of training examples in one forward/backward pass. The higher\n",
    "    the batch size, the more memory space you'll need.\n",
    "    ( 데이터가 너무 클때는 한번에 다 메모리에 올릴 수 없기 때문에 잘라서 하는 크기를 batch size라함)\n",
    "    - number of iterations = number of passes, each pass using [batch size] number of\n",
    "    examples. To be clear, one pass = one forward pass + one backward pass (we do not count the\n",
    "    forward pass and backward pass as two different passes)\n",
    "    \n",
    "Example : if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to\n",
    "complete 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 2.730974971\n",
      "Epoch: 0002, Cost: 1.118662888\n",
      "Epoch: 0003, Cost: 0.890782970\n",
      "Epoch: 0004, Cost: 0.778603967\n",
      "Epoch: 0005, Cost: 0.711240367\n",
      "Epoch: 0006, Cost: 0.658597718\n",
      "Epoch: 0007, Cost: 0.622540341\n",
      "Epoch: 0008, Cost: 0.591759625\n",
      "Epoch: 0009, Cost: 0.566578253\n",
      "Epoch: 0010, Cost: 0.546225149\n",
      "Epoch: 0011, Cost: 0.527936444\n",
      "Epoch: 0012, Cost: 0.513098645\n",
      "Epoch: 0013, Cost: 0.499519464\n",
      "Epoch: 0014, Cost: 0.486372372\n",
      "Epoch: 0015, Cost: 0.475359727\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size) #batch_size 만큼 나눠서 학습\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report results on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 2.873231122\n",
      "Epoch: 0002, Cost: 1.062423050\n",
      "Epoch: 0003, Cost: 0.846743886\n",
      "Epoch: 0004, Cost: 0.742594011\n",
      "Epoch: 0005, Cost: 0.680746537\n",
      "Epoch: 0006, Cost: 0.634488532\n",
      "Epoch: 0007, Cost: 0.598425769\n",
      "Epoch: 0008, Cost: 0.570566192\n",
      "Epoch: 0009, Cost: 0.547830613\n",
      "Epoch: 0010, Cost: 0.527628440\n",
      "Epoch: 0011, Cost: 0.512017730\n",
      "Epoch: 0012, Cost: 0.496754328\n",
      "Epoch: 0013, Cost: 0.485109816\n",
      "Epoch: 0014, Cost: 0.472693587\n",
      "Epoch: 0015, Cost: 0.461576682\n",
      "Learning finished\n",
      "Accuracy:  0.8908\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}\n",
    "        ),# sses.run()도 가능하고 accuracy.eval을 통해서도 실행 가능\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample image show and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning finished\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one and predict\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "#         print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                   feed_dict={X: mnist.test.images[r : r + 1]}),)\n",
    "\n",
    "    plt.imshow(mnist.test.images[r : r + 1].\n",
    "               reshape(28, 28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn",
   "language": "python",
   "name": "inflearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
