{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "x_data = [[1,2,1], [1,3,2], [1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
    "y_data = [[0,0,1], [0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\",[None,3])\n",
    "Y = tf.placeholder(\"float\",[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]), name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.059932 [[ 2.5731013   0.18248442 -1.300221  ]\n",
      " [ 0.3084359  -0.22016734 -0.7529894 ]\n",
      " [-0.26412532  0.6877838  -1.4127742 ]]\n",
      "10 1.8202595 [[ 2.2635245   0.12631996 -0.93448025]\n",
      " [-0.29049063 -0.57507074  0.20084053]\n",
      " [-0.657093    0.24552156 -0.5775443 ]]\n",
      "20 1.5571804 [[ 2.0606534   0.13610053 -0.7413901 ]\n",
      " [-0.3207255  -0.52616256  0.1821673 ]\n",
      " [-0.5823025   0.19892348 -0.6057366 ]]\n",
      "30 1.4086183 [[ 1.8726848   0.14342257 -0.56074345]\n",
      " [-0.32221025 -0.4919095   0.14939897]\n",
      " [-0.50689197  0.15987518 -0.6420989 ]]\n",
      "40 1.2819703 [[ 1.6987628   0.14888117 -0.39228   ]\n",
      " [-0.31448358 -0.46563098  0.11539389]\n",
      " [-0.4451993   0.1300531  -0.67396945]]\n",
      "50 1.17619 [[ 1.5399287   0.15258506 -0.23714979]\n",
      " [-0.3003818  -0.44471365  0.08037489]\n",
      " [-0.3953715   0.10701298 -0.700757  ]]\n",
      "60 1.0889637 [[ 1.395982    0.15490477 -0.09552293]\n",
      " [-0.28239182 -0.427243    0.04491428]\n",
      " [-0.35525376  0.08869682 -0.7225586 ]]\n",
      "70 1.0173452 [[ 1.2658281   0.15629166  0.03324401]\n",
      " [-0.26252595 -0.4119559   0.00976134]\n",
      " [-0.32262003  0.07356707 -0.7400625 ]]\n",
      "80 0.9583905 [[ 1.1479278   0.15716034  0.15027565]\n",
      " [-0.24226457 -0.39811411 -0.02434176]\n",
      " [-0.29544732  0.0605967  -0.7542647 ]]\n",
      "90 0.90952325 [[ 1.0406477   0.1578407   0.2568754 ]\n",
      " [-0.22259685 -0.38534123 -0.05678234]\n",
      " [-0.27208304  0.04916313 -0.7661954 ]]\n",
      "100 0.8686403 [[ 0.94245976  0.15857212  0.35433203]\n",
      " [-0.204118   -0.373475   -0.08712736]\n",
      " [-0.25128043  0.03891255 -0.7767474 ]]\n",
      "110 0.8340827 [[ 0.85202235  0.15951592  0.4438257 ]\n",
      " [-0.18713786 -0.36245883 -0.11512356]\n",
      " [-0.23215243  0.02964549 -0.78660834]]\n",
      "120 0.8045594 [[ 0.76819617  0.1607721   0.5263958 ]\n",
      " [-0.17177415 -0.35227397 -0.14067209]\n",
      " [-0.2140953   0.02123835 -0.7962583 ]]\n",
      "130 0.7790693 [[ 0.6900283   0.16239567  0.60294   ]\n",
      " [-0.15802358 -0.3429037  -0.16379285]\n",
      " [-0.19671312  0.01359947 -0.8060016 ]]\n",
      "140 0.75683385 [[ 0.6167269   0.16440992  0.6742272 ]\n",
      " [-0.14581147 -0.3343197  -0.18458895]\n",
      " [-0.1797552   0.00664788 -0.8160079 ]]\n",
      "150 0.7372459 [[ 5.4763412e-01  1.6681676e-01  7.4091309e-01]\n",
      " [-1.3502522e-01 -3.2647929e-01 -2.0321557e-01]\n",
      " [-1.6306861e-01  3.0584016e-04 -8.2635248e-01]]\n",
      "160 0.719829 [[ 0.48220235  0.16960451  0.8035571 ]\n",
      " [-0.12553568 -0.3193287  -0.21985564]\n",
      " [-0.14656462 -0.00550226 -0.8370483 ]]\n",
      "170 0.70420766 [[ 0.41997406  0.17275336  0.86263657]\n",
      " [-0.11721034 -0.31280792 -0.23470177]\n",
      " [-0.13019547 -0.01084833 -0.8480715 ]]\n",
      "180 0.690084 [[ 0.36056507  0.17623913  0.91855985]\n",
      " [-0.10992087 -0.306855   -0.24794403]\n",
      " [-0.1139384  -0.01579898 -0.859378  ]]\n",
      "190 0.67722005 [[ 0.3036511   0.18003577  0.9716772 ]\n",
      " [-0.1035476  -0.30140948 -0.25976285]\n",
      " [-0.09778603 -0.02041396 -0.8709153 ]]\n",
      "200 0.66542435 [[ 0.24895732  0.1841169   1.0222898 ]\n",
      " [-0.09798115 -0.29641476 -0.27032405]\n",
      " [-0.0817394  -0.02474581 -0.88263005]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 10 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "        \n",
    "        \n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.5793233 [[-0.64321715 -1.0559725  -1.0280048 ]\n",
      " [ 0.46306223 -0.880138    0.54053605]\n",
      " [-0.5917943   1.1246192  -0.47339115]]\n",
      "100 0.7506838 [[-1.611712   -1.1251543   0.00967259]\n",
      " [ 0.13156858 -0.10311084  0.09500265]\n",
      " [ 0.1621108   0.39793155 -0.5006084 ]]\n",
      "200 0.6235938 [[-2.1727214  -1.0790927   0.52462083]\n",
      " [ 0.1818332  -0.01683217 -0.04154035]\n",
      " [ 0.33324462  0.31629303 -0.59010315]]\n",
      "300 0.5579488 [[-2.5917418  -1.0162222   0.8807692 ]\n",
      " [ 0.19740951  0.01017187 -0.08412047]\n",
      " [ 0.48026693  0.28190404 -0.7027365 ]]\n",
      "400 0.5127663 [[-2.9435554  -0.950949    1.1673096 ]\n",
      " [ 0.19996555  0.02639582 -0.10290029]\n",
      " [ 0.6123311   0.25368178 -0.8065784 ]]\n",
      "500 0.47797012 [[-3.2540812  -0.88768667  1.4145737 ]\n",
      " [ 0.19885619  0.03788684 -0.11328176]\n",
      " [ 0.73128384  0.22875099 -0.9006002 ]]\n",
      "600 0.44965568 [[-3.5349407  -0.8281921   1.635939  ]\n",
      " [ 0.19682519  0.04661958 -0.11998321]\n",
      " [ 0.8394062   0.20655191 -0.98652303]]\n",
      "700 0.42586473 [[-3.7926009  -0.77305114  1.8384587 ]\n",
      " [ 0.19474033  0.0535398  -0.12481831]\n",
      " [ 0.9385761   0.18676506 -1.0659059 ]]\n",
      "800 0.40544206 [[-4.03125    -0.72230357  2.0263584 ]\n",
      " [ 0.19287154  0.05917597 -0.12858538]\n",
      " [ 1.030257    0.16912022 -1.139941  ]]\n",
      "900 0.38763183 [[-4.2538743  -0.67574483  2.2024252 ]\n",
      " [ 0.19128114  0.06385389 -0.13167271]\n",
      " [ 1.1155934   0.15337382 -1.2095311 ]]\n",
      "1000 0.37190485 [[-4.462747   -0.63307154  2.368624  ]\n",
      " [ 0.18995722  0.06778944 -0.1342839 ]\n",
      " [ 1.1954963   0.13930856 -1.275369  ]]\n",
      "1100 0.3578737 [[-4.6596594  -0.5939534   2.526418  ]\n",
      " [ 0.18886536  0.07113379 -0.13653617]\n",
      " [ 1.2706975   0.12673175 -1.3379939 ]]\n",
      "1200 0.34524554 [[-4.846064   -0.55806595  2.6769366 ]\n",
      " [ 0.18796723  0.07399791 -0.13850158]\n",
      " [ 1.3417952   0.11547613 -1.3978359 ]]\n",
      "1300 0.33379328 [[-5.0231686  -0.52510595  2.82108   ]\n",
      " [ 0.18722759  0.07646509 -0.14022906]\n",
      " [ 1.4092822   0.1053954  -1.4552416 ]]\n",
      "1400 0.32333797 [[-5.191976   -0.49479765  2.9595795 ]\n",
      " [ 0.18661647  0.07860074 -0.14175345]\n",
      " [ 1.4735687   0.0963626  -1.5104948 ]]\n",
      "1500 0.31373608 [[-5.3533416  -0.4668914   3.0930378 ]\n",
      " [ 0.1861094   0.08045635 -0.14310166]\n",
      " [ 1.5349993   0.08826698 -1.5638301 ]]\n",
      "1600 0.30487132 [[-5.507991   -0.44116497  3.2219603 ]\n",
      " [ 0.1856862   0.08207356 -0.14429545]\n",
      " [ 1.5938668   0.08101258 -1.615443  ]]\n",
      "1700 0.29664826 [[-5.6565514  -0.41741925  3.3467765 ]\n",
      " [ 0.18533075  0.08348644 -0.1453526 ]\n",
      " [ 1.6504208   0.07451513 -1.6654992 ]]\n",
      "1800 0.28898782 [[-5.799569   -0.39547667  3.4678526 ]\n",
      " [ 0.18503064  0.08472318 -0.1462889 ]\n",
      " [ 1.7048757   0.0687004  -1.714139  ]]\n",
      "1900 0.28182378 [[-5.9375157  -0.3751784   3.5855033 ]\n",
      " [ 0.18477502  0.08580715 -0.1471171 ]\n",
      " [ 1.7574174   0.06350319 -1.7614832 ]]\n",
      "2000 0.2751006 [[-6.070812   -0.35638243  3.7000043 ]\n",
      " [ 0.18455635  0.08675846 -0.1478494 ]\n",
      " [ 1.8082076   0.05886484 -1.8076363 ]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1,2,1], [1,3,2], [1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
    "y_data = [[0,0,1], [0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
    "\n",
    "X = tf.placeholder(\"float\",[None,3])\n",
    "Y = tf.placeholder(\"float\",[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "        \n",
    "    \n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))\n",
    "    \n",
    "# rate = 1 -> cost = 0.013679152 \n",
    "# rate = 0.1 -> cost = 0.2728301\n",
    "# rate = 0.01 -> cost = 0.58629334 \n",
    "# rate = 0.01 -> cost = 1.7018555 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate: NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "100 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "200 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "300 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "400 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "500 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "600 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "700 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "800 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "900 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1000 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1100 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1200 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1300 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1400 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1500 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1600 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1700 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1800 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "1900 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "2000 5.9301376 [[-0.32986513  0.8542019   0.11978465]\n",
      " [ 0.08357333  1.6030558  -0.7286192 ]\n",
      " [-0.8831898   0.07583113  1.2545645 ]]\n",
      "Prediction: [1 1 1]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\",[None,3])\n",
    "Y = tf.placeholder(\"float\",[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "        \n",
    "    \n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))\n",
    "    \n",
    "# learning_rate =1.5 이면 rate가 너무커서 밖으로 나가버림\n",
    "# learning_rate= 1e-10이면 rate가 너무 작아서 local minimize에 빠져버림 or 값이 더이상 줄어들지않음,\n",
    "# cost가 계속 12.930634 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-normalized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "# 중간중간에 909100, 1828100처럼 엄청 큰값들이 주어짐\n",
    "# costfunction이 한쪽으로 치우치게 그래프가 그려짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X,W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 128197620000.0 \n",
      "Prediction:\n",
      " [[-252444.83]\n",
      " [-506772.7 ]\n",
      " [-398950.5 ]\n",
      " [-280068.7 ]\n",
      " [-329835.84]\n",
      " [-332596.6 ]\n",
      " [-304940.4 ]\n",
      " [-387868.5 ]]\n",
      "100 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "200 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "300 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "400 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "500 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "600 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "700 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "800 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "900 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1000 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1100 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1200 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1300 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1400 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1500 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1600 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1700 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1800 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1900 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "2000 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "    [cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 ==0:\n",
    "        print(step, \"cost:\", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "        \n",
    "# input data가 non-normalized 되어있기 때문에 cost값이 nan이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 785591040000.0 \n",
      "Prediction:\n",
      " [[ 625614.75]\n",
      " [1259959.9 ]\n",
      " [ 991056.7 ]\n",
      " [ 694572.56]\n",
      " [ 818682.44]\n",
      " [ 825575.3 ]\n",
      " [ 756631.06]\n",
      " [ 963476.1 ]]\n",
      "100 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "200 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "300 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "400 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "500 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "600 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "700 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "800 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "900 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1000 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1100 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1200 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1300 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1400 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1500 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1600 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1700 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1800 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1900 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "2000 cost: nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.matmul(X,W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "    [cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 ==0:\n",
    "        print(step, \"cost:\", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nromalized input (min-max scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = [[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881783 0.83755792]\n",
      " [0.54412549 0.50274824 0.57608696 0.60646801 0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.4258239  0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.4258239  0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "xy=MinMaxScaler().fit_transform(xy)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 0.8732122 \n",
      "Prediction:\n",
      " [[-0.71325815]\n",
      " [-0.6464821 ]\n",
      " [-0.2214247 ]\n",
      " [ 0.25970787]\n",
      " [-0.04772151]\n",
      " [-0.00654906]\n",
      " [ 0.6214989 ]\n",
      " [ 0.61205757]]\n",
      "100 cost: 0.86929834 \n",
      "Prediction:\n",
      " [[-0.7094214 ]\n",
      " [-0.6429827 ]\n",
      " [-0.21856642]\n",
      " [ 0.2618417 ]\n",
      " [-0.04511005]\n",
      " [-0.00404894]\n",
      " [ 0.62295663]\n",
      " [ 0.6134231 ]]\n",
      "200 cost: 0.86541593 \n",
      "Prediction:\n",
      " [[-0.7056011 ]\n",
      " [-0.6394992 ]\n",
      " [-0.2157216 ]\n",
      " [ 0.26396602]\n",
      " [-0.04251033]\n",
      " [-0.00156009]\n",
      " [ 0.6244073 ]\n",
      " [ 0.6147818 ]]\n",
      "300 cost: 0.86155844 \n",
      "Prediction:\n",
      " [[-0.7017913 ]\n",
      " [-0.63602614]\n",
      " [-0.21288526]\n",
      " [ 0.26608306]\n",
      " [-0.0399189 ]\n",
      " [ 0.00092065]\n",
      " [ 0.625852  ]\n",
      " [ 0.6161345 ]]\n",
      "400 cost: 0.85773104 \n",
      "Prediction:\n",
      " [[-0.6979976 ]\n",
      " [-0.63256747]\n",
      " [-0.21006101]\n",
      " [ 0.26819098]\n",
      " [-0.0373385 ]\n",
      " [ 0.00339085]\n",
      " [ 0.62729037]\n",
      " [ 0.61748147]]\n",
      "500 cost: 0.85392946 \n",
      "Prediction:\n",
      " [[-0.694215  ]\n",
      " [-0.629121  ]\n",
      " [-0.20724684]\n",
      " [ 0.2702914 ]\n",
      " [-0.03476703]\n",
      " [ 0.00585234]\n",
      " [ 0.62872255]\n",
      " [ 0.61882174]]\n",
      "600 cost: 0.85015655 \n",
      "Prediction:\n",
      " [[-0.6904474 ]\n",
      " [-0.625688  ]\n",
      " [-0.20444387]\n",
      " [ 0.27238297]\n",
      " [-0.03220594]\n",
      " [ 0.00830382]\n",
      " [ 0.63014853]\n",
      " [ 0.6201563 ]]\n",
      "700 cost: 0.8464098 \n",
      "Prediction:\n",
      " [[-0.68669194]\n",
      " [-0.6222668 ]\n",
      " [-0.2016508 ]\n",
      " [ 0.2744665 ]\n",
      " [-0.02965432]\n",
      " [ 0.01074624]\n",
      " [ 0.631568  ]\n",
      " [ 0.6214845 ]]\n",
      "800 cost: 0.84269154 \n",
      "Prediction:\n",
      " [[-0.6829512 ]\n",
      " [-0.61886036]\n",
      " [-0.19886994]\n",
      " [ 0.276541  ]\n",
      " [-0.02711356]\n",
      " [ 0.01317811]\n",
      " [ 0.63298047]\n",
      " [ 0.6228056 ]]\n",
      "900 cost: 0.83899915 \n",
      "Prediction:\n",
      " [[-0.6792228 ]\n",
      " [-0.6154655 ]\n",
      " [-0.1960988 ]\n",
      " [ 0.27860773]\n",
      " [-0.02458185]\n",
      " [ 0.01560122]\n",
      " [ 0.6343871 ]\n",
      " [ 0.6241211 ]]\n",
      "1000 cost: 0.835333 \n",
      "Prediction:\n",
      " [[-0.67550737]\n",
      " [-0.6120828 ]\n",
      " [-0.19333798]\n",
      " [ 0.28066647]\n",
      " [-0.02205962]\n",
      " [ 0.01801527]\n",
      " [ 0.63578767]\n",
      " [ 0.6254308 ]]\n",
      "1100 cost: 0.83169353 \n",
      "Prediction:\n",
      " [[-0.67180514]\n",
      " [-0.6087135 ]\n",
      " [-0.190588  ]\n",
      " [ 0.28271705]\n",
      " [-0.01954722]\n",
      " [ 0.02041972]\n",
      " [ 0.637182  ]\n",
      " [ 0.62673426]]\n",
      "1200 cost: 0.8280791 \n",
      "Prediction:\n",
      " [[-0.6681148 ]\n",
      " [-0.6053554 ]\n",
      " [-0.1878475 ]\n",
      " [ 0.28476012]\n",
      " [-0.01704353]\n",
      " [ 0.02281588]\n",
      " [ 0.6385707 ]\n",
      " [ 0.6280322 ]]\n",
      "1300 cost: 0.82449317 \n",
      "Prediction:\n",
      " [[-0.6644403 ]\n",
      " [-0.60201216]\n",
      " [-0.18511939]\n",
      " [ 0.2867936 ]\n",
      " [-0.01455128]\n",
      " [ 0.02520084]\n",
      " [ 0.639952  ]\n",
      " [ 0.629323  ]]\n",
      "1400 cost: 0.82093096 \n",
      "Prediction:\n",
      " [[-0.6607762 ]\n",
      " [-0.5986801 ]\n",
      " [-0.18240064]\n",
      " [ 0.28881973]\n",
      " [-0.01206756]\n",
      " [ 0.02757758]\n",
      " [ 0.64132744]\n",
      " [ 0.6306077 ]]\n",
      "1500 cost: 0.8173962 \n",
      "Prediction:\n",
      " [[-0.6571276 ]\n",
      " [-0.59536123]\n",
      " [-0.1796931 ]\n",
      " [ 0.2908373 ]\n",
      " [-0.00959426]\n",
      " [ 0.02994436]\n",
      " [ 0.64269686]\n",
      " [ 0.631887  ]]\n",
      "1600 cost: 0.8138844 \n",
      "Prediction:\n",
      " [[-0.65348876]\n",
      " [-0.5920533 ]\n",
      " [-0.17699432]\n",
      " [ 0.292848  ]\n",
      " [-0.00712895]\n",
      " [ 0.03230339]\n",
      " [ 0.6440606 ]\n",
      " [ 0.6331604 ]]\n",
      "1700 cost: 0.8103997 \n",
      "Prediction:\n",
      " [[-0.649865  ]\n",
      " [-0.5887591 ]\n",
      " [-0.17430693]\n",
      " [ 0.29485023]\n",
      " [-0.00467408]\n",
      " [ 0.03465241]\n",
      " [ 0.6454183 ]\n",
      " [ 0.63442814]]\n",
      "1800 cost: 0.8069389 \n",
      "Prediction:\n",
      " [[-0.64625293]\n",
      " [-0.5854761 ]\n",
      " [-0.17162937]\n",
      " [ 0.2968443 ]\n",
      " [-0.00222826]\n",
      " [ 0.03699261]\n",
      " [ 0.64676934]\n",
      " [ 0.6356894 ]]\n",
      "1900 cost: 0.8035044 \n",
      "Prediction:\n",
      " [[-6.4265478e-01]\n",
      " [-5.8220732e-01]\n",
      " [-1.6896319e-01]\n",
      " [ 2.9882985e-01]\n",
      " [ 2.0718575e-04]\n",
      " [ 3.9322793e-02]\n",
      " [ 6.4811403e-01]\n",
      " [ 6.3694412e-01]]\n",
      "2000 cost: 0.8000938 \n",
      "Prediction:\n",
      " [[-0.6390689 ]\n",
      " [-0.5789495 ]\n",
      " [-0.16630644]\n",
      " [ 0.30080807]\n",
      " [ 0.00263393]\n",
      " [ 0.04164457]\n",
      " [ 0.6494532 ]\n",
      " [ 0.6381936 ]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.matmul(X,W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "    [cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 ==0:\n",
    "        print(step, \"cost:\", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
